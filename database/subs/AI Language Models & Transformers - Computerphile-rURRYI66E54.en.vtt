WEBVTT
Kind: captions
Language: en

00:00:00.089 --> 00:00:02.089
cSo I wanted to make a video about

00:00:02.439 --> 00:00:03.490
GPT - 2

00:00:03.490 --> 00:00:05.109
Because it's been in the news recently

00:00:05.109 --> 00:00:10.499
this very powerful language model from open AI and I thought it would make sense to start by just doing a video about

00:00:11.920 --> 00:00:14.429
transformers and language models in general because

00:00:15.549 --> 00:00:17.549
GPT 2 is a very large

00:00:17.800 --> 00:00:23.880
Language model implemented as a transformer, but you have a previous video about generating YouTube comments, which is the same kind of task, right?

00:00:23.880 --> 00:00:30.150
That's a language modeling task from language processing to generate new samples for cooling of the most complex or magnetic

00:00:30.369 --> 00:00:34.679
Consistent brackets like a computer to expect found in creating organizations

00:00:34.800 --> 00:00:41.640
I believe that video was made October 2017 and this paper came out December 2017, which has kind of

00:00:42.160 --> 00:00:47.849
Revolutionized the way that people carry out that kind of task. That's not the GPT -  2 that's something before that, right?

00:00:47.910 --> 00:00:52.199
That's the transformer, which is a new realm. Yeah relatively new

00:00:52.840 --> 00:00:54.370
architecture

00:00:54.370 --> 00:00:59.189
for neural networks, that can do actually all kinds of tasks, but they're especially good at this kind of

00:00:59.920 --> 00:01:01.920
language modeling task

00:01:04.489 --> 00:01:08.929
a language model is a probability distribution over like sequences of

00:01:10.920 --> 00:01:13.489
Tokens or symbols or words or whatever in a language?

00:01:13.490 --> 00:01:17.540
So for any given like sequence of tokens, it can tell you how likely that is

00:01:17.880 --> 00:01:20.720
So if you have a good language model of English

00:01:21.060 --> 00:01:27.619
It can look at a sequence of you know words or characters or whatever and say how likely that is to occur in English

00:01:28.680 --> 00:01:31.909
How likely that is to be an English phrase or sentence or whatever

00:01:32.460 --> 00:01:37.429
And when you have that you can use that for a lot of different tasks. So

00:01:38.550 --> 00:01:46.369
If you want to generate text, then you can you can just sort of sample from that distribution and keep giving it

00:01:47.039 --> 00:01:49.039
its own output

00:01:49.110 --> 00:01:51.800
so you you sample a word and then you say

00:01:52.950 --> 00:01:55.909
And to be clear sampling from a distribution means you're just taking

00:01:56.729 --> 00:02:02.928
Your you're sort of rolling the dice on that probability distribution and taking whichever one comes out. So

00:02:04.229 --> 00:02:06.709
so you can like sample a word and then

00:02:07.530 --> 00:02:13.399
And then say okay conditioning on that given that the first word of this sentence is V

00:02:13.890 --> 00:02:16.549
What does the probability distribution look like for the second word?

00:02:16.549 --> 00:02:19.039
And then you sample from that distribution and then it's you know

00:02:19.290 --> 00:02:24.229
with a cat and you say given that it's the cat what's likely to come next and so on so you can you can build

00:02:24.230 --> 00:02:25.890
up a

00:02:25.890 --> 00:02:27.890
string of text by sampling from

00:02:28.170 --> 00:02:30.500
Your distribution that's one of the things you could use it for

00:02:30.930 --> 00:02:34.160
most of us kind of have an example of this sort of in our pockets of

00:02:34.620 --> 00:02:41.360
Its actual absolutely right and that's like that's the that's the way that most people interact with a language model

00:02:41.360 --> 00:02:45.320
I guess this is how I often start a sentence

00:02:45.870 --> 00:02:53.299
apparently with I I am not sure if you have any questions or concerns, please visit the

00:02:53.820 --> 00:03:00.559
Plugin settings so I can do it for the first time in the future of that's no good

00:03:00.660 --> 00:03:03.649
Here's a different option. Let's just see what this way. Maybe the same

00:03:03.650 --> 00:03:05.900
I am in the morning

00:03:05.970 --> 00:03:13.790
But I can't find it on the phone screen from the phone screen on the phone screen on the phone screen on the phone screen

00:03:15.030 --> 00:03:17.899
On the phone screen. I don't actually know how this is implemented

00:03:17.970 --> 00:03:21.859
it might be a neural network, but my guess is that it's some kind of

00:03:22.800 --> 00:03:26.539
like Markov model Markov chain type setup where you just

00:03:27.060 --> 00:03:32.750
for each word in your language you look at your data set and you see how often a particular

00:03:33.360 --> 00:03:35.360
how often each other word is

00:03:36.120 --> 00:03:39.380
Following that word and then that's how you build your distribution

00:03:39.380 --> 00:03:45.469
So like for the word "I" the most common word to follow that is "am" and there are a few others, you know

00:03:45.470 --> 00:03:47.470
so this is like a very simple model and

00:03:47.850 --> 00:03:51.889
This sentence on the phone screen on the phone screen on the phone screen on the phone screen on the phone screen

00:03:52.020 --> 00:03:54.409
He's actually very unlikely, right?

00:03:54.410 --> 00:04:00.919
This is the super low probability sentence where I would somebody type this and the thing is it's like myopic

00:04:00.959 --> 00:04:05.539
It's only I'm not sure I even it's probably only looking at the previous word

00:04:05.540 --> 00:04:10.790
It might be looking at like the previous two words, but the problem is to look back. It becomes extremely expensive

00:04:11.760 --> 00:04:13.550
Computationally expensive right?

00:04:13.550 --> 00:04:20.089
Like you've got I don't know 50,000 words that you might be looking at and so then it so you're you're you're remembering

00:04:20.430 --> 00:04:22.430
50,000 probability distributions or

00:04:22.890 --> 00:04:24.260
50,000 top three words

00:04:24.260 --> 00:04:26.269
but you know then if you want to do

00:04:26.610 --> 00:04:29.750
2, that's 50,000 squared right and if you want to go back three words

00:04:29.750 --> 00:04:34.850
You have to cube it. So you like raising it to the power of the number of words back you want to go which is

00:04:35.520 --> 00:04:37.520
Which means that this type of model?

00:04:38.070 --> 00:04:43.159
Basically doesn't look back by the time we're saying on the it's already forgotten the previous time

00:04:43.160 --> 00:04:49.309
It said on the it doesn't realize that it's repeating itself and there are slightly better things you can do in this general area

00:04:49.380 --> 00:04:53.899
But like fundamentally if you don't remember you're not going to be able to make good sentences

00:04:53.900 --> 00:04:57.859
If you can't remember the beginning of the sentence by the time you're at the end of it, right?

00:04:58.590 --> 00:04:59.790
and

00:04:59.790 --> 00:05:01.169
so

00:05:01.169 --> 00:05:06.559
One of the big areas of progress in language models is handling long term dependencies

00:05:06.740 --> 00:05:10.490
I mean handling dependencies of any kind but especially long term dependencies

00:05:10.490 --> 00:05:16.820
You've got a sentence that's like Shawn came to the hack space to record a video and I talked to

00:05:17.460 --> 00:05:21.979
Blank right in that situation if your model is good

00:05:21.979 --> 00:05:27.219
you're expecting like a pronoun probably so it's it's she they

00:05:28.070 --> 00:05:32.469
You know them whatever and but the relevant piece of information is the words short

00:05:33.050 --> 00:05:35.229
Which is like all the way at the beginning of the sentence

00:05:35.230 --> 00:05:38.800
so your model needs to be able to say oh, okay, you know Shawn that's

00:05:39.410 --> 00:05:46.179
Usually associated with male pronouns, so we'll put the male pronoun in there. And if your model doesn't have that ability to look back

00:05:46.880 --> 00:05:49.989
Or to just remember what it's just said then

00:05:50.900 --> 00:05:52.900
You end up with these sentences that?

00:05:53.000 --> 00:05:54.100
Like go nowhere

00:05:54.100 --> 00:05:56.100
It's just a slight like it might make a guess

00:05:56.120 --> 00:05:59.799
just a random guess at a pronoun and might get it wrong or it might just

00:06:00.500 --> 00:06:02.649
and I talked to and then just be like

00:06:03.290 --> 00:06:10.480
Frank, you know just like introduced a new name because it's guessing at what's likely to come there and it's completely forgotten that sure was

00:06:10.480 --> 00:06:17.349
Ever like a thing. So yeah, these kind of dependencies are a big issue with things that you would want to language model to do

00:06:18.500 --> 00:06:20.500
But we've only so far talked about

00:06:21.410 --> 00:06:28.450
Language models for generating text in this way, but you can also use them for all kinds of different things. So like

00:06:29.750 --> 00:06:31.779
people use language models for translation

00:06:31.880 --> 00:06:39.010
Obviously you have some input sequence that's like in English and you want to output a sequence in French or something like that

00:06:39.410 --> 00:06:43.299
Having a good language model is really important so that you end up with something. That makes sense

00:06:43.940 --> 00:06:46.029
Summarization is a task that people often want

00:06:46.130 --> 00:06:51.159
Where you read in a long piece of text and then you generate a short piece of text. That's like a summary of that

00:06:51.590 --> 00:06:54.790
that's the kind of thing that you would use a language model for or

00:06:56.210 --> 00:06:59.620
reading a piece of text and then answering questions about that text or

00:06:59.900 --> 00:07:05.410
If you want to write like a chatbot that's going to converse with people having a language model as good like basically almost all

00:07:05.690 --> 00:07:07.690
like natural language processing

00:07:07.910 --> 00:07:10.689
right is it's useful to have this the other thing is

00:07:11.450 --> 00:07:13.450
You can use it to enhance

00:07:15.380 --> 00:07:18.159
Enhance a lot of other language related tasks

00:07:18.160 --> 00:07:22.660
So if you're doing like speech recognition then having a good language model

00:07:22.660 --> 00:07:26.799
Like there's a lot of things people can say that sound very similar and to get the right one

00:07:27.260 --> 00:07:30.640
You need to be like, oh, well, this actually makes sense, you know

00:07:31.370 --> 00:07:33.370
This word. That sounds very similar

00:07:34.070 --> 00:07:36.609
Would be incoherent in this sentence. It's a very low probability

00:07:36.680 --> 00:07:40.750
It's much more likely that they this thing which is like would flow in the language

00:07:41.210 --> 00:07:44.109
And human beings do this all the time same thing

00:07:45.500 --> 00:07:48.760
With recognizing text from images, you know

00:07:48.760 --> 00:07:53.349
You've got two words that look similar or there's some ambiguity or whatever and to resolve that you need

00:07:53.690 --> 00:07:54.350
an

00:07:54.350 --> 00:07:59.200
understanding of what word would make sense there what word would fit if you're trying to use a neural network to do the kind of

00:07:59.200 --> 00:08:03.980
thing we were talking about before, of having a phone, you know autocorrect based on the previous word or two

00:08:04.020 --> 00:08:09.420
Suppose you've got a sequence of two words going in you've got "so" and then "I" and you put

00:08:09.560 --> 00:08:14.350
both of these into your network and it will then output, you know

00:08:14.350 --> 00:08:19.989
like "said" for example as like a sensible next word and then what you do is you throw away or so and you then

00:08:20.390 --> 00:08:22.390
Bring your set around and you make a new

00:08:23.120 --> 00:08:27.700
Sequence which is I said and then put that into your network and it will put out

00:08:27.700 --> 00:08:33.369
like I said - for example would make sense and so on and you keep going around, but the problem is

00:08:33.620 --> 00:08:38.409
This length is really short you try and make this long enough to contain an entire

00:08:39.169 --> 00:08:44.019
Sentence just an ordinary length sentence and this problem starts to become really really hard

00:08:44.690 --> 00:08:48.760
And networks have a hard time learning it and you don't get very good performance

00:08:49.580 --> 00:08:51.580
and even then

00:08:51.620 --> 00:08:57.099
You're still like have this absolute hard limit on how long a thing you you have to just pick a number

00:08:57.100 --> 00:09:02.350
That's like how far back am I looking a better thing to do you say recurring neural network? Where you

00:09:02.720 --> 00:09:04.720
You give the thing. Let's like divide that up

00:09:04.850 --> 00:09:08.140
So in this case, then you have a network you give it this vector?

00:09:08.140 --> 00:09:12.969
You just like have a bunch of numbers which is gonna be like the memory

00:09:13.310 --> 00:09:17.500
for that network is the idea like the problem is it's forgotten in the beginning of the sentence by the time it gets to the

00:09:17.500 --> 00:09:19.780
end so we've got to give it some way of remembering and

00:09:20.300 --> 00:09:24.880
rather than feeding it the entire sentence every time you give it this vector and

00:09:25.730 --> 00:09:28.780
you give it to just one word at a time of your inputs and

00:09:29.510 --> 00:09:33.129
This vector, which you initialize I guess with zeros. I want to be clear

00:09:33.130 --> 00:09:36.010
This is not something that I've studied in a huge amount of detail

00:09:36.010 --> 00:09:41.200
I'm just like giving the overall like structure of the thing. But the point is you give it this vector and the word and

00:09:41.900 --> 00:09:45.759
it outputs its guess for the next word and also a

00:09:46.400 --> 00:09:51.039
Modified version of that vector that you then for the next thing you give it

00:09:51.580 --> 00:09:53.770
where did it spit out or the sequence that it spit out and

00:09:54.110 --> 00:09:59.409
Its own modified version of the vector every cycle that goes around. It's modifying this memory

00:09:59.450 --> 00:10:02.049
Once this system is like trained very well

00:10:02.050 --> 00:10:07.870
If you give it if you give it the first word Shawn then part of this vector is going to contain some

00:10:08.390 --> 00:10:12.009
information that's like this subject of this sentence is the word short and

00:10:12.560 --> 00:10:14.679
some other part will probably keep track of like

00:10:15.470 --> 00:10:20.199
We expect to use a male pronoun for this sentence and that kind of thing

00:10:20.200 --> 00:10:26.920
So you take this and give it to that and these are just two instances of the same network, and then it keeps going

00:10:27.410 --> 00:10:28.520
every time

00:10:28.520 --> 00:10:34.660
So it spits out like this is I so then the AI also comes around to here you might then put outside and so on

00:10:34.670 --> 00:10:37.659
But it's got this continuous thread of

00:10:38.990 --> 00:10:45.549
of memory effectively going through because it keeps passing the thing through in principle if it figures out something important at the beginning of

00:10:45.860 --> 00:10:47.450
You know

00:10:47.450 --> 00:10:50.830
The complete works of Shakespeare that it's generating. There's nothing

00:10:51.470 --> 00:10:55.389
Strictly speaking stopping that from persisting from being passed through

00:10:56.150 --> 00:10:59.530
From from iteration to iteration to iteration every time

00:11:00.440 --> 00:11:04.270
In practice, it doesn't work that way because in practice

00:11:04.970 --> 00:11:12.339
The whole thing is being messed with by the network on every step and so in in the training process it's going to learn

00:11:13.100 --> 00:11:18.850
That it performs best when it leaves most of it alone and it doesn't just randomly change the whole thing

00:11:19.010 --> 00:11:22.059
But by the time you're on the fiftieth word of your sentence

00:11:22.760 --> 00:11:27.069
whatever the network decided to do on the first word of the sentence is a

00:11:27.290 --> 00:11:30.369
photocopy of a photocopy of a photocopy of a photocopy and so

00:11:31.370 --> 00:11:33.370
things have a tendency to

00:11:33.620 --> 00:11:38.410
Fade out to nothing. It has to be successfully remembered at every step of this process

00:11:38.410 --> 00:11:40.899
and if at any point it gets overwritten with something else or just

00:11:41.420 --> 00:11:46.089
It did its best to remember it but it's actually remembering 99% of it each time point nine

00:11:46.090 --> 00:11:48.910
Nine to the fifty is like actually not that big of a number

00:11:48.910 --> 00:11:56.319
So these things work pretty well, but they still get the performance like really quickly drops off once the sentences start to get long

00:11:56.320 --> 00:11:58.689
So this is a recurrent neural network

00:11:59.300 --> 00:12:02.139
rnl because all of these boxes

00:12:03.500 --> 00:12:09.429
Are really the same box because this is the same network at different time steps. It's really a loop like this

00:12:09.429 --> 00:12:15.129
You're giving the output of the network back as input every time so this works better and then people have tried all kinds of interesting

00:12:15.129 --> 00:12:20.199
Things things like LS TMS. There's all kinds of variants on this general like recurrent Network

00:12:20.720 --> 00:12:26.949
LS TM is the thing. That might use isn't it? Right right long short-term memory, which is kind of surreal

00:12:26.949 --> 00:12:30.488
But yeah, so the idea of that is it's a lot more complicated inside these networks

00:12:30.489 --> 00:12:36.219
There's actually kind of sub networks that make specific decisions about gating things. So

00:12:36.799 --> 00:12:43.358
Rather than having to have this system learn that it ought to pass most things on it's sort of more in the architecture that passes

00:12:43.359 --> 00:12:47.589
most things on and then there's a there's a sub there's like part of the learning is

00:12:48.619 --> 00:12:50.029
Deciding what to forget

00:12:50.029 --> 00:12:55.178
At each step and like deciding what to change and what to put it in what parcel and so on and they perform better

00:12:55.249 --> 00:12:58.389
They can hang on to the information the relevant information for longer

00:13:00.499 --> 00:13:05.738
But the other thing that people often build into these kinds of systems is something called attention

00:13:06.709 --> 00:13:10.298
Which is actually a pretty good metaphor

00:13:11.089 --> 00:13:13.089
Where in the same way that you would have?

00:13:13.549 --> 00:13:18.819
networks that decide which parts of your hidden state to hang on to or which starts to forget or

00:13:20.239 --> 00:13:22.478
Those kinds of decisions like gating and stuff

00:13:23.929 --> 00:13:31.329
You have a system which is deciding which parts of the input to pay attention to which parts to use in

00:13:31.669 --> 00:13:38.769
The in the calculation and which parts to ignore and this turns out to be actually very powerful. So there was this paper

00:13:39.679 --> 00:13:40.999
When was this?

00:13:40.999 --> 00:13:42.049
2000

00:13:42.049 --> 00:13:46.299
2017. Yeah, so this is funny because this came out the same year as

00:13:46.879 --> 00:13:53.108
The video you have about generating YouTube comments. This is in December. I think that video was October ancient history now

00:13:53.109 --> 00:13:59.679
Alright, we're talking two years ago. The idea of this is as its called attention is all you need. They developed this system. Whereby

00:14:00.259 --> 00:14:02.149
it's actually as

00:14:02.149 --> 00:14:04.298
it's a lot simpler as a

00:14:05.869 --> 00:14:10.928
As a network you can see on the diagram here if you compare this to the diagram for an LS TM or

00:14:11.539 --> 00:14:17.679
Any of those kind of variants? It's relatively simple and it's just kind of using attention to do everything

00:14:18.049 --> 00:14:24.419
So when made that video the ASTM type stuff was like state-of-the-art and that was until a couple of months later

00:14:24.420 --> 00:14:31.440
I guess when this paper came out the idea of this is that attention is all you need of it like this stuff about

00:14:32.050 --> 00:14:34.680
having gates for forgetting things and

00:14:36.160 --> 00:14:40.529
All of that all of that kind of stuff in fact your whole recurrence like architecture

00:14:41.500 --> 00:14:45.239
you can do away with it and just use attention attention is powerful enough to

00:14:45.940 --> 00:14:51.659
do everything that you need at its base attention is about actively deciding in the same way that

00:14:53.139 --> 00:15:00.359
the LS TM is actively deciding what to forget and so on this is deciding which parts of

00:15:01.000 --> 00:15:03.419
some other part of the data it's going to

00:15:03.550 --> 00:15:08.579
take into account which parts it's going to look at like it can be very dangerous in AI to

00:15:09.639 --> 00:15:13.859
use words for things that are words that people already use

00:15:14.380 --> 00:15:18.989
For the way that humans do things. It makes it very easy transform for more finds and just

00:15:19.690 --> 00:15:26.549
make, you know get confused because the abstraction doesn't quite work but I think attention is a pretty decent thing because it is

00:15:27.519 --> 00:15:28.560
It does make sense

00:15:28.560 --> 00:15:32.819
It sort of draws the relationships between things so you can have attention from the output to the input

00:15:33.040 --> 00:15:38.040
Which is what that would be you can also have attention from the output to other parts of the output

00:15:38.560 --> 00:15:42.419
so for example when I'm generating in that sentence like

00:15:43.000 --> 00:15:46.949
Shawn came to record a video or whatever by the time I get to generating the word him

00:15:46.949 --> 00:15:49.469
I don't need to be thinking about the entire sentence

00:15:49.470 --> 00:15:52.620
I can just focus my attention on where I remember

00:15:52.930 --> 00:15:59.010
The name was so the attention goes to Shawn and then I can make the decision for to use the word him based on

00:15:59.560 --> 00:16:00.670
that

00:16:00.670 --> 00:16:02.649
so

00:16:02.649 --> 00:16:05.879
so rather than having to hang on to a huge amount of memory you

00:16:07.810 --> 00:16:13.079
Can just selectively look at the things that are actually relevant and the system learns

00:16:13.480 --> 00:16:18.509
Where to look where to pay attention to and that's really cool like you can do it

00:16:18.540 --> 00:16:22.889
There's attention based systems for all kinds of things like not just text you can do

00:16:24.279 --> 00:16:28.469
Like suppose you have your input is like an image and you want to caption it

00:16:28.470 --> 00:16:33.050
You can actually look at when it was outputting the sequence you can say when you generated the word dog

00:16:33.420 --> 00:16:37.370
What was your you can get like an attention heat map and it will highlight the dog

00:16:37.440 --> 00:16:41.690
Because that's the part of the image that it was paying attention to when it generated that output

00:16:41.690 --> 00:16:48.049
It makes your system more interpretable because you can see what it was thinking and sometimes you can catch problems that way as well

00:16:48.050 --> 00:16:49.560
which is kind of fun like

00:16:49.560 --> 00:16:55.879
It generates the output that's like a man is lifting a dumbbell or something like that and you look at it

00:16:55.879 --> 00:17:01.219
And it's not actually correct. It's like its owner trots and I go he's drinking some tea out of a mug, right and

00:17:02.100 --> 00:17:04.100
what you find is then when you look at your

00:17:04.199 --> 00:17:11.089
Outputs where it says dumbbell you look at the attention and the attention is like mostly looking at the arms. That's usually somebody muscular

00:17:11.089 --> 00:17:12.559
Who's lifting the dumbbell in your photos?

00:17:12.559 --> 00:17:17.538
It's and so it it's overriding the fact that this kind of looks like a mug because it was looking at the arms

00:17:17.539 --> 00:17:22.729
So the idea is this system which is called a transformer is a type of neural network

00:17:22.730 --> 00:17:25.880
which just relies very heavily on attention to

00:17:26.429 --> 00:17:30.949
Produce like state-of-the-art performance and if you train them on a large

00:17:31.860 --> 00:17:34.669
corpus of natural language they can learn

00:17:36.539 --> 00:17:41.569
They can learn to do very well, right they give you they can be very powerful language models

00:17:41.570 --> 00:17:44.059
We had the example of a language model on your phone

00:17:44.059 --> 00:17:49.699
That's like a very very basic and then trying to do this with neural networks and the problems with remembering

00:17:50.340 --> 00:17:56.449
And so you have like recurrent systems that keep track of they allow you to pass memory along so that you can remember the beginning

00:17:56.450 --> 00:17:58.760
of the sentence at least by the end of it and

00:17:59.520 --> 00:18:03.889
Things like LSTMs there is all these different varieties that people try different things

00:18:05.130 --> 00:18:09.949
That are better and hanging on to memory so that they can do better it they can have longer term

00:18:10.080 --> 00:18:12.980
Dependencies, which allows you to have more coherent

00:18:14.400 --> 00:18:15.539
outputs

00:18:15.539 --> 00:18:19.519
in just generally better performance, and then the transformer is

00:18:20.280 --> 00:18:22.280
Is a variant on that?

00:18:22.409 --> 00:18:30.409
Well is a different way of doing things where you really focus on attention. And so these are actually not recurrent which is an

00:18:31.049 --> 00:18:33.979
important distinction to make we don't have this thing of like

00:18:34.169 --> 00:18:37.369
Taking the output and feeding that back as the input and so on every time

00:18:37.890 --> 00:18:42.319
Because we have attention. We don't need to keep a big memory

00:18:43.350 --> 00:18:50.640
That we run through every time when the system wants to know something it can use its attention to look back to that part

00:18:50.980 --> 00:18:54.419
It's not like memorizing the text as it goes. It's

00:18:54.970 --> 00:18:57.360
paying attention to different bits of the text as

00:18:58.059 --> 00:19:01.499
they as it thinks that they're relevant to the bit that it's looking at now and

00:19:02.740 --> 00:19:05.459
The thing about that is when you have this recurrent thing

00:19:05.890 --> 00:19:07.890
It's kind of inherently serial

00:19:07.900 --> 00:19:10.979
most of the calculations for this you can't do them until you have

00:19:11.410 --> 00:19:15.659
The inputs and the inputs are the output of the previous network. And so

00:19:16.270 --> 00:19:20.729
You can't do the thing that people like to do now, which is run it on a million computers

00:19:21.309 --> 00:19:26.219
And get lightning-fast performance because you have to go through them in order right? It's like inherently serial

00:19:27.130 --> 00:19:32.760
Where as transformers are much more parallelizable, which means you get better computational performance out of them as well?

00:19:34.120 --> 00:19:36.120
Which is another

00:19:36.130 --> 00:19:40.829
Selling point so they they work better and they run faster. So they're they're really a

00:19:41.740 --> 00:19:44.370
Step up. So transformers. Are this really powerful

00:19:45.460 --> 00:19:51.659
architecture.  They seem to give really good performance on this kind of sort of language modeling type tasks and

00:19:52.840 --> 00:19:53.890
we

00:19:53.890 --> 00:19:58.439
But what we didn't know really was how far you can push them or how how good they can get

00:19:58.720 --> 00:20:06.059
What happens if you take this architecture and you give it a bigger data set than any of them has ever been given and more?

00:20:06.370 --> 00:20:11.010
Compute to train with, you know, a larger model with more parameters and more data

00:20:11.320 --> 00:20:15.299
How good can these things get how how good a language model?

00:20:15.299 --> 00:20:18.779
Can you actually make and that's what opening I was doing with GPT 2?

00:20:19.780 --> 00:20:27.089
So an executable binary the net effect of slotting that T diagram against here slightly downwards is to show you

00:20:28.450 --> 00:20:34.169
That the C you've written gets converted into binary and the net output from this

00:20:34.990 --> 00:20:38.819
process it produces out a program that you probably store in a

