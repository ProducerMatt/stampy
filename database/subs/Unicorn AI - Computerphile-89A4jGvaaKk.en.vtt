WEBVTT
Kind: captions
Language: en

00:00:00.030 --> 00:00:02.030
In the previous video we were talking about

00:00:02.350 --> 00:00:06.690
transformers this architecture that uses attention to give

00:00:07.180 --> 00:00:11.400
Unprecedented ly good performance on sort of language modeling tasks and some other tasks as well

00:00:11.400 --> 00:00:15.630
but when were looking at language modeling and that was in preparation to make a video about

00:00:16.539 --> 00:00:22.919
GPG 2, which is this very giant language model that has been there was recently

00:00:23.439 --> 00:00:29.099
Well, it was recently not released actually by open AI the way that they generated the data set for this is pretty cool

00:00:29.920 --> 00:00:33.719
to get enough text they went to Reddit and

00:00:34.510 --> 00:00:42.329
They pulled every website that is linked to from reddit. Do we have any idea of how many days lots?

00:00:45.810 --> 00:00:48.499
Literally, everything was everything that had more than three karma

00:00:48.500 --> 00:00:50.630
I think or maybe more than two karma something like that like

00:00:50.790 --> 00:00:56.089
Anything that had somebody had thought to post around it and at least two or three people who had thought was good enough to upload

00:00:56.700 --> 00:01:01.130
They scraped the text from that. It's pretty much just a transformer. It's not the the

00:01:01.890 --> 00:01:05.120
Architecture is not especially novel. They haven't done any like amazing new

00:01:06.330 --> 00:01:08.330
new discovery, but

00:01:08.460 --> 00:01:10.460
What they realized was?

00:01:12.690 --> 00:01:14.690
Transformers it seems like

00:01:14.729 --> 00:01:20.599
the more data you give them the better they do and the bigger you make them the better they do and

00:01:21.630 --> 00:01:24.799
Everything that we built up until this point is clearly not

00:01:25.950 --> 00:01:28.040
Like we haven't hit the limits of what this can do

00:01:29.340 --> 00:01:32.360
We they thought we think we're probably

00:01:33.390 --> 00:01:37.099
Bottle necked on data and maybe network size

00:01:37.100 --> 00:01:41.570
So what happens if we'd like to turn that 211 what happens if we just give this all?

00:01:41.700 --> 00:01:47.420
The data and make a really big one. It makes sense to talk about the acronym right so it's a generative pre-training

00:01:47.970 --> 00:01:53.479
Transformer so generative same as generative adversarial network. It generates outputs to generate samples

00:01:53.479 --> 00:01:57.288
Your pre-trained is this thing. I was talking about all of the different things

00:01:57.289 --> 00:02:01.729
You can use a language model for right you can do you can do translation. You can try and resolve ambiguities

00:02:01.729 --> 00:02:07.699
You can do summarization. You can answer questions. You can use the probabilities for augmenting other systems

00:02:08.130 --> 00:02:11.240
So yeah, there's a bunch of different benchmarks for these different tasks

00:02:11.760 --> 00:02:13.850
that you might want your language model to do and

00:02:14.250 --> 00:02:20.809
This is what we talked about in the grid worlds video of having these like standardized problems with standardized metrics and standardized data sets

00:02:20.810 --> 00:02:24.110
So that if you're comparing two different methods, you know that you're actually comparing apples to apples

00:02:24.870 --> 00:02:29.810
And this is like very important it gives you numbers on these things. It's often quite difficult

00:02:30.930 --> 00:02:38.000
Expected to like you're generating samples of text and it's like how plausible is this text? How realistic does it look like?

00:02:38.000 --> 00:02:42.050
How do you put a number on that it's kind of difficult. So there's all of these standardized metrics and

00:02:42.810 --> 00:02:44.810
the thing that

00:02:45.599 --> 00:02:49.999
People came to realize which actually I mean I say that as though it's like some amazing discovery

00:02:50.000 --> 00:02:56.930
It's fairly obvious. If you train your system in a like an unsupervised way on a large corpus of just general English text and

00:02:57.630 --> 00:02:59.630
then you take that and

00:03:00.060 --> 00:03:04.129
Train that with the data from this benchmark or the data from that benchmark

00:03:04.519 --> 00:03:08.029
You can like fine-tune it so you start with something which has like a decent

00:03:08.340 --> 00:03:13.340
Understanding of how English works more or less and then you say now I'm going to give you these

00:03:14.730 --> 00:03:20.359
Samples for like question answering or I'm going to build a system using that to solve to go for this benchmark

00:03:20.359 --> 00:03:26.869
So it's pre trained you start with something. That's like a general-purpose language model and then you from that a

00:03:27.750 --> 00:03:29.519
Fine-tuned it to whichever

00:03:29.519 --> 00:03:31.519
Actual benchmark or problem you're trying to solve

00:03:32.280 --> 00:03:34.280
and this

00:03:34.379 --> 00:03:39.379
Can give you better performance than to starting from nothing and training to each of the benchmarks from scratch

00:03:40.349 --> 00:03:42.030
make sense

00:03:42.030 --> 00:03:43.889
and so

00:03:43.889 --> 00:03:51.709
The point of the GPT 2 paper the thing that makes it cool is they said okay if we make a really huge one

00:03:53.040 --> 00:03:54.959
What if we?

00:03:54.959 --> 00:03:56.010
don't

00:03:56.010 --> 00:03:58.010
Fine tune it at all

00:03:58.109 --> 00:04:03.499
What if we just make a giant model and then just try and run it on the benchmarks without messing with it?

00:04:03.690 --> 00:04:08.809
Without showing it any of their specialized data for that benchmark. Just the raw

00:04:09.510 --> 00:04:13.639
general-purpose language model, how does that perform and it turns out

00:04:14.730 --> 00:04:17.359
surprisingly well, so this is a

00:04:18.120 --> 00:04:20.479
Very very large data set for text

00:04:21.150 --> 00:04:23.150
It's about 40 gigabytes

00:04:23.580 --> 00:04:25.289
which

00:04:25.289 --> 00:04:30.379
Actually doesn't sound like very much but like for text text that's insane, right? It's

00:04:31.020 --> 00:04:33.020
somebody said that this was the size of

00:04:33.479 --> 00:04:36.408
Google's entire index of the Internet in 98

00:04:37.050 --> 00:04:39.229
So like it's yeah, it's a lot of text

00:04:40.620 --> 00:04:43.669
and they trained it on that and they ended up with a

00:04:44.220 --> 00:04:51.199
1.5 billion parameter model, but which is like a previous state of the art system was 345 million

00:04:51.210 --> 00:04:52.699
This is 1.5 billion

00:04:52.699 --> 00:04:58.459
So they've just made the thing much much bigger and it performs really well some of their samples that they published quite

00:04:59.220 --> 00:05:00.810
captured the public imagination

00:05:00.810 --> 00:05:05.389
You could say and now that we've talked a little about the problems that

00:05:06.090 --> 00:05:08.840
Neural networks or any language model really?

00:05:09.479 --> 00:05:11.479
Has with a long term dependency

00:05:11.990 --> 00:05:18.010
we can now realise just how impressive these samples are because when you look at them as a you know,

00:05:18.010 --> 00:05:21.069
If you look at them uninitiated, you're like yeah, that's pretty realistic

00:05:21.070 --> 00:05:26.320
It seems to like make sense and it's cool. But when you look at it knowing how language models work, it's like

00:05:26.960 --> 00:05:30.790
very impressive the the coherence and the

00:05:31.310 --> 00:05:36.729
Consistency and the long-range dependencies so we can look at this one that got everybody's attention the unicorns one

00:05:36.729 --> 00:05:36.970
right

00:05:36.970 --> 00:05:41.949
So they prompted it with in a shocking finding scientists discovered a herd of unicorns

00:05:42.290 --> 00:05:45.519
living in a remote previously unexplored valley in the Andes Mountains

00:05:45.889 --> 00:05:49.839
Even more surprising to the researchers was the fact that the unicorns spoke perfect English

00:05:50.780 --> 00:05:57.579
And from there you then say you go to your language model gbgt, and you say given that we started with this

00:05:58.220 --> 00:06:01.059
What's the next word and what's the word after that and so on?

00:06:02.330 --> 00:06:08.229
So it goes on the scientist named the population after their distinctive horn of its unicorn

00:06:08.630 --> 00:06:12.639
These four horned silver white unicorns were previously unknown to science

00:06:12.639 --> 00:06:17.079
We do have a clue here as a human being unicorns for horned doesn't quite make sense

00:06:17.419 --> 00:06:19.989
But nonetheless we're going okay

00:06:20.210 --> 00:06:26.169
Now after almost two centuries the mystery of what sparked this odd phenomenon is finally solved. Dr

00:06:26.479 --> 00:06:28.479
Budetti Jorge Jorge Perez

00:06:28.760 --> 00:06:32.379
Jo are G an evolutionary biologist from the University of La Paz

00:06:32.380 --> 00:06:39.010
This is impressive because we've mentioned the Andes Mountains in our prompt and so now it's saying okay

00:06:39.740 --> 00:06:44.260
This is clearly, you know in a shocking finding. This is a science press release news article

00:06:44.260 --> 00:06:49.689
It's seen enough of those because it has every single one that was ever linked to from reddit, right?

00:06:50.360 --> 00:06:54.010
So it knows how these go it knows. Okay third paragraph

00:06:55.729 --> 00:06:59.649
This is when we talk about the scientist, we interview the scientist, right? Okay

00:07:00.470 --> 00:07:06.399
First word of the scientist paragraph, dr. Obviously, right because this is the now we're in the name of the scientist

00:07:06.400 --> 00:07:08.150
What name are we going to give?

00:07:08.150 --> 00:07:09.830
It needs to be a name

00:07:09.830 --> 00:07:12.520
conditioning on the fact that we have the Andes Mountains

00:07:13.099 --> 00:07:15.579
So we need to get where we're in South America

00:07:16.340 --> 00:07:19.659
The name probably should be Spanish or maybe Portuguese

00:07:20.450 --> 00:07:22.749
So we get we get dr. Perez here

00:07:23.770 --> 00:07:28.810
And then evolutionary biologist makes sense because we're talking about animals

00:07:29.780 --> 00:07:32.019
from the University of La Paz again

00:07:32.539 --> 00:07:38.259
This is the first sentence like when you have that first clause that introduces the scientist you always say where they're from

00:07:38.379 --> 00:07:42.969
So we say from the University of and then university names tend to be the name of a city

00:07:43.129 --> 00:07:47.829
What's the city where we have the Andes Mountains, so we're going to Bolivia lapaz. Perfect

00:07:47.830 --> 00:07:53.979
And the thing that's cool about this is it's remembered all of these things that were quite a long time ago several sentences ago

00:07:53.979 --> 00:07:58.779
Well, it hasn't remembered them. It's paid attention to them across that distance, which is impressive

00:07:58.909 --> 00:08:05.229
But also this is encoding a bunch of understand understanding a bunch of information about the real world

00:08:05.659 --> 00:08:12.849
Right all that was given all it knows is statistical relationships between words, but the way that it comes out to us

00:08:12.849 --> 00:08:13.970
Is that it knows?

00:08:13.970 --> 00:08:20.979
Where the Andes Mountains are what kind of names people in that area have what their cities are what the universities are all of those

00:08:22.009 --> 00:08:29.288
Facts about the real world because in order to have a really good language model it turns out you have to kind of implicitly encode

00:08:30.710 --> 00:08:32.710
information about the world because

00:08:33.169 --> 00:08:36.819
We use language to talk about the world and knowing what's likely to come next

00:08:37.490 --> 00:08:42.130
Requires actual real world understanding and that's something that we see in some of the other

00:08:43.010 --> 00:08:46.419
Things that they got it to do you can see the real world understanding coming through

00:08:46.430 --> 00:08:47.570
Let's keep going

00:08:47.570 --> 00:08:54.129
University of a person several companions were exploring the Andes Mountains when they found a small valley with no other animals or humans peres see

00:08:54.620 --> 00:08:57.279
We're hanging on to him. Yep. We're referring to him again

00:08:57.950 --> 00:09:01.539
but now we've changed it to be just the surname because that's the

00:09:01.610 --> 00:09:07.060
format that people use in news articles Peres noticed that the valley had what appeared to be a natural fountain surrounded by two peaks of

00:09:07.060 --> 00:09:11.500
Rock and silver snow presently others, then ventured further into the valley a round about here in our article

00:09:11.500 --> 00:09:13.510
We should have a quote from the scientist right quote

00:09:13.570 --> 00:09:18.849
By the time we reached the top of one peak the water looked blue with some crystals on top and we're talking about this fountain

00:09:18.850 --> 00:09:22.690
I guess it's natural fountain. We're referring back to the previous int. It's like everything is

00:09:23.600 --> 00:09:30.250
Relying on in contingent on earlier parts of the text while examining there by snipped paragraph while examining these bizarre

00:09:30.350 --> 00:09:36.660
Creatures the scientists discovered that the creatures also spoke some fairly regular English know when I read that I like, okay

00:09:36.660 --> 00:09:42.809
this is now unusually good because that's the second sentence of the lead right where six paragraphs in and

00:09:42.970 --> 00:09:46.889
It knows about this point. I've covered the first sentence of this

00:09:47.440 --> 00:09:48.460
initial paragraph

00:09:48.460 --> 00:09:52.800
now it's time to talk about this second sentence of the lead even more surprising to the research of us of the fact that they

00:09:52.800 --> 00:09:53.860
spoke English and

00:09:53.860 --> 00:09:59.309
It completely ignored the speaking English part until it got to the part of the news article where that comes in

00:09:59.460 --> 00:10:01.300
You've gone six whole paragraphs

00:10:01.300 --> 00:10:02.800
the idea of

00:10:02.800 --> 00:10:05.099
Accurately remembering that the unicorn speak perfect

00:10:05.100 --> 00:10:10.230
English is like that's very impressive to me and then it goes into its gets a little bit unhinged

00:10:11.620 --> 00:10:16.230
Starts talking about it's likely that the only way of knowing for sure if unicorns are indeed

00:10:16.230 --> 00:10:20.039
The descendants of a lost alien race is through DNA. That's read it really

00:10:21.100 --> 00:10:26.879
Well, it's not actually stuff on reddit. It's stuff linked to from reddit. But yeah, this is this is news articles men

00:10:27.460 --> 00:10:30.030
They seem to be able to communicate in English quite well

00:10:30.430 --> 00:10:35.519
Which I believe is a sign of evolution or at least a change in social organization said the scientist

00:10:35.740 --> 00:10:42.599
That's his evolutionary biology there. Right? Right, right. Yeah, we know here's an evolutionary biologist. So so the the

00:10:43.570 --> 00:10:45.570
coherence of this text is

00:10:46.600 --> 00:10:48.600
really dependent on its ability to

00:10:49.630 --> 00:10:51.630
Condition what it's generating on

00:10:52.090 --> 00:10:54.119
Things that it's generated a long time ago

00:10:54.120 --> 00:10:54.810
So yeah

00:10:54.810 --> 00:11:02.760
So it can generate really nice news articles and it can generate all kinds of text things that it anything that is

00:11:03.220 --> 00:11:08.579
Sufficiently well represented in the original data set. So that's GPG - it's a really

00:11:09.220 --> 00:11:12.899
Unusually powerful and like versatile

00:11:13.480 --> 00:11:17.159
language model that can do all of these different natural language processing

00:11:17.620 --> 00:11:21.750
Tasks without actually being trained specifically on those tasks

00:11:22.750 --> 00:11:25.680
It's really and that's that's why it's impressive

00:11:25.680 --> 00:11:29.129
It's not that it's a it's a brand new architecture or a brand new approach or whatever

00:11:29.130 --> 00:11:33.150
It's just when you make these things really huge and give them tremendously large amounts of data

00:11:33.940 --> 00:11:36.300
The results are really impressive

00:11:37.060 --> 00:11:42.210
In the original data set. So it will it will write you the Lord of the Rings fan fiction

00:11:42.490 --> 00:11:48.780
It will write you cake recipes if we're like, there's all kinds of examples of different samples. Here's a recipe for

00:11:51.570 --> 00:11:56.460
Some kind of peppermint chocolate cake and it's got a bunch of different

