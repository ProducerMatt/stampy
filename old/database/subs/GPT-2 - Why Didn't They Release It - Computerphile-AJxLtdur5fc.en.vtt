WEBVTT
Kind: captions
Language: en

00:00:00.030 --> 00:00:03.540
So, I think it's worth talking a little bit because like I'm usually talking to you about

00:00:04.420 --> 00:00:05.920
safety

00:00:05.920 --> 00:00:10.469
About the decision that opening I made to not release the fully trained

00:00:11.290 --> 00:00:13.290
Model the big one

00:00:14.889 --> 00:00:21.989
So because this has not been released we know that it works like a transformer left to its own devices without being

00:00:22.330 --> 00:00:27.149
Fine-tuned it's just a massive amount of data and off you go. Is that right?

00:00:27.400 --> 00:00:31.679
Yeah, like there's enough information given in the paper to reproduce it

00:00:32.410 --> 00:00:33.610
and

00:00:33.610 --> 00:00:38.939
you just need the giant giant data set which is a real hassle to make especially because

00:00:41.140 --> 00:00:46.680
You really need high quality data, does it say anywhere in the paper about how long it took to train

00:00:47.680 --> 00:00:49.300
Yes

00:00:49.300 --> 00:00:53.340
And how and how many different how many TP use you need and stuff like that?

00:00:54.420 --> 00:00:55.930
What's the TPU?

00:00:55.930 --> 00:00:57.930
That's a tensor processing unit

00:00:58.000 --> 00:00:58.500
Okay

00:00:58.500 --> 00:01:00.539
So like a GPU, but fancy

00:01:00.670 --> 00:01:07.680
you need a lot of money if you tried to train this with just like amazon's cloud computing offering you would be

00:01:08.110 --> 00:01:13.709
You'd end up with a bill that I I expect would be in the hundreds of thousands of pounds like it's a lot of compute

00:01:15.159 --> 00:01:19.139
But with all of these things it's a lot of compute to train them. It's not that much computer run

00:01:19.140 --> 00:01:22.379
This isn't a new architecture. This isn't like a vast breakthrough

00:01:23.080 --> 00:01:26.309
From that perspective. It's just like the same thing but much bigger and

00:01:28.180 --> 00:01:34.529
And nobody else is keeping their research and like not releasing their models to the public

00:01:35.170 --> 00:01:40.739
So, you know, you think it's dangerous to say that you think that your work might be dangerous and you're not releasing it

00:01:40.740 --> 00:01:45.659
It's kind of like you think it's much more dangerous than other people's work and therefore like it's so powerful that it's dangerous

00:01:45.700 --> 00:01:48.570
it's kind of like you're saying that your stuff is so good that

00:01:49.479 --> 00:01:54.179
It's you know, it's too powerful for you. You know, I can't release it or whatever

00:01:54.180 --> 00:01:57.569
I think people reacted in a sense to that

00:01:58.450 --> 00:02:01.259
There's just smack a little bit of publicity stunt

00:02:01.259 --> 00:02:06.629
I mean assuming it's not a publicity stunt assume rest is not that which I don't believe it is what are they worried about?

00:02:07.929 --> 00:02:10.109
So that the worry like people make a big

00:02:11.470 --> 00:02:16.520
People make a big deal of the Evette generating fake news like fake news

00:02:16.800 --> 00:02:23.809
Articles that will convince people that there are actually unicorns or whatever. I don't think that that's the risk

00:02:23.810 --> 00:02:28.640
I also don't think that that's really what opening. I thinks the risk is if you want to generate a fake thing

00:02:28.640 --> 00:02:32.690
It's still not expensive to do that. You can just sit down and write something right

00:02:32.690 --> 00:02:35.600
You don't need a language model to write your fake news

00:02:36.180 --> 00:02:37.230
and

00:02:37.230 --> 00:02:39.499
In fact, you don't have that much control over it

00:02:39.810 --> 00:02:44.300
So you wouldn't if you were trying to actually manipulate something you would want to be tweaking it

00:02:44.300 --> 00:02:47.029
anyway, I don't think that's the risk the the thing that

00:02:48.180 --> 00:02:51.349
the thing that most concerns me about things like gbg 2 is

00:02:52.710 --> 00:03:00.139
Like the content is not particularly good but it is convincingly human and so it creates a lot of potential for making fake

00:03:00.390 --> 00:03:01.830
users

00:03:01.830 --> 00:03:03.390
and

00:03:03.390 --> 00:03:06.529
So there is this constant arms race between bots

00:03:07.080 --> 00:03:12.320
Operators and the big platforms right? There's teams working at Google at YouTube at Facebook everywhere

00:03:12.840 --> 00:03:14.730
working on identifying

00:03:14.730 --> 00:03:17.659
Accounts that aren't real and there's various ways. You can do that

00:03:18.630 --> 00:03:23.179
one of the things you can do is you can analyze the text that they write because the language models that are out there aren't

00:03:23.180 --> 00:03:28.670
Very good. And so if some if if an account is like repeating itself a lot

00:03:29.580 --> 00:03:33.740
Or you have a whole bunch of accounts that are all saying like exactly the same thing

00:03:33.960 --> 00:03:37.579
Then you know that this is like a spam maybe manipulation attempt and so on

00:03:38.400 --> 00:03:39.530
But with GPT, too

00:03:39.530 --> 00:03:41.430
You can have things that produce

00:03:41.430 --> 00:03:47.000
you give the same prompt and then you post all of the outputs and all of those outputs are different from each other and

00:03:47.340 --> 00:03:49.490
They all look like they were written by a human

00:03:50.460 --> 00:03:52.460
and it's not a

00:03:52.470 --> 00:03:54.710
Human can look at them probably and figure out

00:03:56.100 --> 00:03:58.129
Hang on a second. This doesn't quite seem right

00:03:59.040 --> 00:04:01.159
But only if you're really really paying attention

00:04:02.190 --> 00:04:03.300
which

00:04:03.300 --> 00:04:10.880
Human attention on the large scale is super expensive right so much more expensive than the compute needed to generate the samples

00:04:10.880 --> 00:04:15.200
So you're outmatched if you if you spend more they can spend it you can you can spend

00:04:15.840 --> 00:04:22.250
10 times more and you cripple yourself financially and they can spend 10 times more and it's fine. So you're gonna lose that battle

00:04:23.720 --> 00:04:31.720
The other thing is so it becomes very difficult to identify fake users. The other thing is one way that you can identify fake users

00:04:32.419 --> 00:04:34.190
is by

00:04:34.190 --> 00:04:38.320
Analyzing the graph like the social graph or the interaction graph and you can see that

00:04:40.880 --> 00:04:41.900
Because

00:04:41.900 --> 00:04:47.620
Humans, usually when they see spam posts that are full of links to dubious websites and whatever

00:04:48.169 --> 00:04:50.829
They download them. They don't reply to them and

00:04:51.740 --> 00:04:57.970
You can create you can fake the voting metrics by having these accounts vote for each other's stuff

00:04:58.100 --> 00:05:01.719
But then you can analyze the graph of that and say oh all of these plate people

00:05:01.789 --> 00:05:06.129
They all only vote for each other and the people who we know are humans like never vote for them

00:05:06.350 --> 00:05:09.579
So we assume those are all bots and we can ignore them

00:05:11.150 --> 00:05:18.039
But the samples that gbt to produces the big model are convincing enough to get actual humans to engage with them

00:05:18.039 --> 00:05:24.129
Right. It's not like oh my god, that's so persuasive. I've read this article and now I believe this thing about unicorns

00:05:24.410 --> 00:05:29.109
It's just like I believe that a real human wrote this thing and now I want to argue with them

00:05:29.690 --> 00:05:31.959
That there aren't unicorns or whatever, right?

00:05:31.960 --> 00:05:38.530
And now you have real humans engaging in actual meaningful conversation with BOTS

00:05:39.080 --> 00:05:40.280
and

00:05:40.280 --> 00:05:44.589
Now you've got a real problem because how are you going to spot who the bots are?

00:05:45.349 --> 00:05:48.219
When you can't do it automatically just by analyzing the text

00:05:48.320 --> 00:05:55.570
You can't even do it by aggregating the human responses to them because the humans keep thinking that they're actual humans

00:05:55.699 --> 00:05:58.239
so now you have the ability to produce large amounts of

00:05:59.000 --> 00:06:02.109
fake users that the platforms can't spot and

00:06:02.330 --> 00:06:08.289
therefore they can't stop those users votes from counting on things up voting things and down voting things and liking them and

00:06:08.539 --> 00:06:14.229
subscriptions and everything else and maybe plating the metrics that way one thing people would do is spot the

00:06:15.860 --> 00:06:20.410
Their profile pictures if you're trying to generate a large number of BOTS

00:06:20.410 --> 00:06:24.579
where are you going to get your pictures from and so you can do like reverse image search and get the

00:06:25.099 --> 00:06:31.239
Find of it and they're all using the same picture or they're all using pictures from the same database of facial photos or whatever

00:06:31.460 --> 00:06:36.729
Now we have these really good generative adversarial networks that can generate good-looking cases

00:06:37.130 --> 00:06:41.799
So that's now really difficult as well and like you can't automatically detect those

00:06:42.410 --> 00:06:48.429
Almost by definition because the way the gams work the discriminator is like a state-of-the-art fake face image detector

00:06:48.430 --> 00:06:52.000
and it's being fooled like that's the whole point and if you released

00:06:52.520 --> 00:06:57.880
If somebody came up with a really reliable way of spotting those fake images then

00:07:00.139 --> 00:07:02.709
You can just use that as the discriminator and keep training

00:07:02.780 --> 00:07:03.349
right

00:07:03.349 --> 00:07:06.309
so not releasing their full strength model to me feels

00:07:06.620 --> 00:07:12.130
Very sensible in the sense that people will figure it out, right they published the the science

00:07:12.500 --> 00:07:18.369
Someone will find it. It is worth their while to do it to spend the money to reproduce these results, but

00:07:19.580 --> 00:07:23.349
By not releasing it. They've bought the platform's

00:07:24.169 --> 00:07:28.269
Several months to like prepare for this to understand what's going on and they are of course

00:07:28.340 --> 00:07:34.149
Working with them and sharing their full strength model with selected partners people. They trust to say here's what it can do

00:07:35.150 --> 00:07:36.669
Take a moment

00:07:36.669 --> 00:07:42.969
You know govern yourself accordingly like get ready because this stuff is going to come but they're giving everybody a heads up to

00:07:43.280 --> 00:07:50.919
Mitigate the potential like negative impacts that this work might have and the other thing is it sets a really good precedent

00:07:50.919 --> 00:07:52.430
I think

00:07:52.430 --> 00:07:55.120
Because maybe GPG - isn't that dangerous?

00:07:55.909 --> 00:07:59.979
but the stuff that we're making is just getting more and more powerful and

00:08:00.889 --> 00:08:05.739
at some point somebody is going to develop something that is really dangerous and by then you want there to be

00:08:06.259 --> 00:08:07.310
accepted

00:08:07.310 --> 00:08:09.820
practices and social norms and industry standards

00:08:10.400 --> 00:08:14.679
About thinking about the impact of your work before you release it

00:08:15.199 --> 00:08:17.060
and

00:08:17.060 --> 00:08:21.969
So it's good to start with something that like there's some argument that there could be some danger from it

00:08:22.159 --> 00:08:25.899
just so that everybody is like aware that this is a thing that you can do and

00:08:26.030 --> 00:08:33.159
that people won't think you're weird or you're bragging or it's a publicity stunt or whatever to make it like socially okay to say

00:08:33.500 --> 00:08:39.130
we found this cool result and we're not going to put it out there because we're not sure about the safety of it and

00:08:39.349 --> 00:08:45.609
I think that that's something that's really really necessary. So I think that open AI is very smart to

00:08:46.250 --> 00:08:48.250
Start that off now

00:08:48.550 --> 00:08:50.550
For we really really need it. I

00:08:50.870 --> 00:08:52.760
Make a principled

00:08:52.760 --> 00:08:53.890
decision now

00:08:53.890 --> 00:08:54.920
I want the seven

00:08:54.920 --> 00:08:55.959
so in principle

00:08:55.959 --> 00:09:00.699
I should be going this way right and would think I'd want to steer towards the seven but on the other hand at

00:09:00.950 --> 00:09:06.189
This point it's your choice. You give it some random noise and it generates an image

00:09:06.769 --> 00:09:10.059
From that noise and the idea is its supposed

