WEBVTT
Kind: captions
Language: en

00:00:00.030 --> 00:00:06.809
We're six paragraphs in and it knows about this point, I've covered the first sentence of this initial paragraph

00:00:07.569 --> 00:00:11.909
now it's time to talk about this second sentence of the lead even more surprising to the researchers than the fact that they

00:00:11.910 --> 00:00:13.000
spoke English and

00:00:13.000 --> 00:00:18.660
it completely ignored the speaking English part until it got to the part of the news article where that comes in and

00:00:18.760 --> 00:00:20.340
Now it's talking about it

00:00:20.340 --> 00:00:26.069
Which is the kind of thing that these kinds of systems would have real trouble doing I've known journalists who can't write that well

00:00:29.289 --> 00:00:31.150
If that ties into

00:00:31.150 --> 00:00:34.619
Something that I think is kind of fundamental to the way that people think about AI

00:00:34.930 --> 00:00:38.849
like we used to think that you had to be really clever to be good at chess and if you could play chess then you

00:00:38.850 --> 00:00:39.820
Were real?

00:00:39.820 --> 00:00:45.930
Intelligence you had to be and then we realized that like playing chess to a superhuman level doesn't require something that we would call

00:00:46.360 --> 00:00:51.119
Intelligence and it's slightly unsettling to find that like writing coherent and plausible

00:00:51.430 --> 00:00:55.259
News prose apparently also doesn't require general intelligence

00:00:56.170 --> 00:00:59.940
like if you just learn the statistical relationships between words

00:01:00.789 --> 00:01:04.349
But do that really really well that seems to be enough

00:01:04.350 --> 00:01:09.269
I mean obviously any journalist would would say that the truth is kind of important in this as well

00:01:09.280 --> 00:01:13.379
But yeah to make it sound plausible. You're absolutely right, right

00:01:14.590 --> 00:01:20.189
Yeah there so there's there's definitely questions about like directing this towards producing a specific article

00:01:20.189 --> 00:01:22.889
that is correct, but

00:01:24.369 --> 00:01:30.239
just the generating of the of the prose itself apparently requires less like

00:01:31.840 --> 00:01:34.590
Philosophical sophistication than we thought

00:01:35.409 --> 00:01:38.249
Then many thought anyway, I think 10 years ago

00:01:39.490 --> 00:01:42.269
People would have a really hard time believing that

00:01:42.880 --> 00:01:49.290
Something that's just learning from data and learning these relative probabilities could produce something this coherent

00:01:49.630 --> 00:01:53.100
you would expect it to have all sorts of conditions and a formula and

00:01:54.729 --> 00:01:58.769
An uncoded you would look at this and say oh this must have like a database of

00:01:59.290 --> 00:02:01.210
names and countries

00:02:01.210 --> 00:02:02.620
locations and

00:02:02.620 --> 00:02:06.419
Cities and everything else because it's using that information, but it turns out all of that

00:02:06.580 --> 00:02:10.410
Is already represented in the data set because we're talking about all these things

00:02:10.869 --> 00:02:16.799
Here's a recipe for some kind of peppermint chocolate cake, and it's got a bunch of different completions

00:02:17.410 --> 00:02:20.249
so you can just spit these out arbitrarily so

00:02:20.470 --> 00:02:27.419
You know those recipe blogs where like you google the recipe for something and you go to the blog and there's like seven paragraphs

00:02:27.550 --> 00:02:33.059
Of like my mother used to make this for me back in our home in, Indiana

00:02:33.240 --> 00:02:36.329
I always remember sitting out on the porch with my dog

00:02:36.640 --> 00:02:38.640
He used to you know

00:02:38.709 --> 00:02:44.999
The important thing is I had an onion on my belt which was the style at the time and and it's doing that

00:02:45.040 --> 00:02:47.040
It's like talking about

00:02:47.650 --> 00:02:53.520
Different back stories. Yeah, just back story and um I wonder if anyone was trying to make any of these recipes

00:02:54.220 --> 00:02:56.110
Yeah, it's dangerous

00:02:56.110 --> 00:02:58.110
this one

00:02:58.600 --> 00:03:01.229
So this is this is a recipe for meringue cookies

00:03:01.750 --> 00:03:07.679
1 and 3/4 cups butter softened the cup of sugar and egg yolk 3 t of heavy

00:03:08.530 --> 00:03:10.860
Critical T. What unit? Is that 3 tons? Heavy cream?

00:03:11.410 --> 00:03:15.600
That's usually a lowercase T. I don't know what it is 3 tons of heavy cream. Let's say

00:03:16.300 --> 00:03:19.109
three and a half to four cups of flour pinch of salt

00:03:19.660 --> 00:03:25.709
Peppermint Jojo topping which like I have no idea what that is, but peppermint. Jo jo's is mentioned in the prompt

00:03:25.709 --> 00:03:30.238
So one and a quarter cups powdered sugar a cup of chopped pecans a half a cup

00:03:30.310 --> 00:03:34.199
Finely chopped mint leaves 1/2 cup chopped fresh mint about a half sheet

00:03:34.330 --> 00:03:38.010
So it's like it doesn't quite make sense, but it's right on the edge of making sense

00:03:38.200 --> 00:03:40.709
like we have half a cup of chopped mint leaves and

00:03:41.320 --> 00:03:48.719
Then also half a cup of chopped fresh mint all these potentially cherry picked out of a huge number of horrendous

00:03:48.790 --> 00:03:52.529
Right. Yes. So this is these ones specifically or not

00:03:52.600 --> 00:03:58.139
So the unicorn one and this is something that I like and it's standard practice, but I like this the unicorn one

00:03:58.140 --> 00:04:01.559
It says they specifically said right now we're gonna make a sample for the paper

00:04:01.630 --> 00:04:06.059
They made 10 of them and they picked the one they liked which was this one but for the recipes here

00:04:06.060 --> 00:04:09.450
These are not cherry picked at all. That's why they're showing 6 they just gone

00:04:09.450 --> 00:04:11.450
This is the first six that we generated

00:04:11.550 --> 00:04:16.140
And here they are and there so that gives you a better idea of the general quality of what it's putting out

00:04:16.140 --> 00:04:19.110
They're all fairly sensible. I like look at this world, right?

00:04:19.150 --> 00:04:22.830
this one comes in and says I do not substitute it with something else blah blah and then

00:04:23.470 --> 00:04:26.610
Like this, I don't know if that is right

00:04:26.610 --> 00:04:28.560
Here's an image or yeah

00:04:28.560 --> 00:04:33.480
Please like this on Facebook and then it goes on I found this really cute card with cute little

00:04:33.610 --> 00:04:39.779
Kittens on and then as your samples cut off, so it's just like next post in the blog or you know

00:04:39.780 --> 00:04:42.330
This is why GPT-2 is so cool to me. Let's see

00:04:42.330 --> 00:04:46.949
The first thing they tested on is a children's book test where this is. I think it's like a closed thing

00:04:47.950 --> 00:04:52.619
Where you just have it have a data set with some children's books and then you like remove one word

00:04:53.890 --> 00:04:58.679
And then the system has to predict which of the words is the correct

00:04:59.080 --> 00:05:03.359
Like you give it you give it ten words that it might be or something like that and it has to pick what word fits

00:05:03.360 --> 00:05:08.340
In this space. So that's standard kind of language model type task. The one thing that they did have to do is

00:05:09.490 --> 00:05:14.070
they had to run analysis to check about overlap and it turns out that one of the

00:05:14.350 --> 00:05:16.770
Children's books is the jungle book by Rudyard Kipling

00:05:16.990 --> 00:05:23.910
Which was actually in in its entirety was in the data set that they trained the thing on so he just knew that one

00:05:24.220 --> 00:05:28.260
So then they threw that out because I think that's not fair if you've already seen the entire book before

00:05:29.919 --> 00:05:35.909
And it's performance on that was was good by the time they guts up to the to the very large scale models

00:05:35.910 --> 00:05:37.810
Its scoring one. Is that eighty?

00:05:37.810 --> 00:05:40.919
eighty nine percent where humans tend to get like

00:05:41.530 --> 00:05:43.649
ninety 90 to 93 percent

00:05:44.070 --> 00:05:49.919
It's like nearly a human level for guessing one missing word from a sentence in a children's book pretty good

00:05:50.320 --> 00:05:56.010
Lambada is designed to test long-range dependencies, which is what I've been talking about a lot

00:05:56.010 --> 00:06:02.999
The task is to predict the final word of sentences which require at least 50 tokens of context for a human to successfully predict

00:06:03.100 --> 00:06:05.429
It's like 50 words is a pretty long sentence

00:06:06.100 --> 00:06:08.100
and

00:06:08.590 --> 00:06:13.590
So this kind of long-term dependency thing is a standard way of testing language models and

00:06:15.250 --> 00:06:17.820
It ends up with an accuracy of 63 percent

00:06:18.580 --> 00:06:23.759
Which is an improvement over state of the art by four percent. So it's state of the art on Lambada without

00:06:24.550 --> 00:06:28.750
Being specifically trained on that just running in general the winograd schema

00:06:28.750 --> 00:06:31.089
I don't know if it's support if you know event venal guard. Who knows

00:06:31.700 --> 00:06:33.380
Maybe it's somebody's name

00:06:33.380 --> 00:06:39.340
Whatever. This is about resolving ambiguities, which is really especially important in

00:06:40.310 --> 00:06:42.310
translation tasks and things like that

00:06:43.100 --> 00:06:46.960
it's very easy for sentences to be ambiguous in a way that

00:06:48.200 --> 00:06:50.200
Makes translating them

00:06:50.390 --> 00:06:56.590
Very difficult or even impossible and I have like I have an example of this check this out. So consider a sentence like

00:06:58.910 --> 00:07:01.929
The chicken didn't cross the road because it was too black

00:07:02.300 --> 00:07:06.280
okay, and then we can consider different versions of this sentence suppose that this is

00:07:07.550 --> 00:07:11.319
Wide chicken didn't cross the road because it was too wide, right?

00:07:12.740 --> 00:07:15.879
That's like one possible completion for this or you might say

00:07:16.940 --> 00:07:19.450
The chicken didn't cross the road because it was too scared

00:07:20.120 --> 00:07:23.109
another perfectly sensible sentence, then the question is

00:07:24.320 --> 00:07:25.340
it

00:07:25.340 --> 00:07:26.930
in one of these

00:07:26.930 --> 00:07:32.680
It is referring to the chicken and in one of them. It is referring to the road color for a third and sure

00:07:33.200 --> 00:07:34.400
stormy

00:07:34.400 --> 00:07:42.309
Stormy. Oh, yeah. Alright. That's a good one. So stormy means it is actually neither of the things in the sentence

00:07:42.980 --> 00:07:45.099
the other one that's fun is something like

00:07:46.340 --> 00:07:47.840
busy

00:07:47.840 --> 00:07:52.239
Right. Is it a busy road or did the chicken just have better things to do than crossing the road?

00:07:52.490 --> 00:07:54.490
We don't know. I mean like I

00:07:54.560 --> 00:07:57.580
Would say probably the road but this could be a children's book, right?

00:07:57.830 --> 00:08:03.220
We are running this thing on children's books. The rabbit. The rabbit was too busy. It was late for an important date

00:08:03.220 --> 00:08:05.220
why can't that she can be busy so

00:08:05.600 --> 00:08:12.520
The point is suppose. We're trying to translate this into a language the genders everything as many languages do and

00:08:13.250 --> 00:08:18.970
Maybe chicken is like a is a masculine noun and Road is a feminine noun and it has to know

00:08:19.820 --> 00:08:21.620
What it's about right?

00:08:21.620 --> 00:08:26.109
Is this like is this L or L or whatever so the idea of this benchmark is?

00:08:26.720 --> 00:08:31.299
measuring how well it can resolve ambiguities because if this says wide if you're trying to do

00:08:32.090 --> 00:08:34.389
Translation the old old-fashioned way

00:08:34.940 --> 00:08:38.869
Where you're like parsing trees and looking things up in dictionaries and stuff like that

00:08:38.870 --> 00:08:45.799
This kind of sentence is the hell nightmare because you can't you don't know. I mean, you just don't know the information is not

00:08:46.350 --> 00:08:48.350
really present in the

00:08:49.320 --> 00:08:55.400
Text it's not present grammatically. It's present in your understanding of the world and chickens and roads, right?

00:08:56.460 --> 00:09:00.590
So translating this if this is it was too wide and you translate it

00:09:01.320 --> 00:09:07.789
Into something which is the equivalent of the English sentence the chicken cross the road because the chicken was too wide you've screwed up

00:09:07.800 --> 00:09:10.669
Right, that's a bad translation. But at the same time

00:09:11.580 --> 00:09:16.369
Like there's nothing in the sentence that tells you that it shouldn't be right

00:09:16.410 --> 00:09:20.960
so what you need to do is the same this the thing that we've already seen that GPT 2 is super good at

00:09:21.120 --> 00:09:23.040
Which is pulling in knowledge of the world

00:09:23.040 --> 00:09:28.310
Like knowing that the University of La Paz is going to be near the Andes or in the Andes right that kind of thing

00:09:28.310 --> 00:09:29.610
It's going to know

00:09:29.610 --> 00:09:30.270
that

00:09:30.270 --> 00:09:36.829
Roads being wide is a thing much more than chickens being wide is a thing and so on and that like roads don't get scared

00:09:36.830 --> 00:09:40.639
If it's scared crazy fearless, so again on this kind of thing, it does very well

00:09:40.640 --> 00:09:44.359
It beats the state of the art by a lot. You can see on this graph here

00:09:44.360 --> 00:09:48.050
So the way that this graph is laid out, by the way, this is the same in all of them

00:09:48.050 --> 00:09:54.919
This is the size of the model. They made four different sizes of model. And these are like the same sizes that previous

00:09:55.950 --> 00:10:00.169
Language models were so they were like make sense to compare them their previous to the small ones

00:10:00.170 --> 00:10:01.470
They do worse than the state of the art

00:10:01.470 --> 00:10:08.180
But then these seven hundred sixty two million parameter and the 1.5 billion parameter significantly past state of the art

00:10:08.180 --> 00:10:11.450
They're getting like 70 percent. So the state of the art is the straight line across, right?

00:10:11.450 --> 00:10:11.840
Yes

00:10:11.840 --> 00:10:17.239
And the thing that is also kind of fun about some of these graphs is so some of them they're seven six two

00:10:17.700 --> 00:10:23.179
million and the 1.5 billion end up doing about as well as each other, which means you've like hit the limit of I

00:10:23.700 --> 00:10:29.450
Get maybe your data set or whatever. Whereas in this one. They're still growth which means an even bigger model

00:10:29.450 --> 00:10:32.929
We might expect to do even better maybe reading comprehension

00:10:33.150 --> 00:10:36.799
This is another thing you have some text you then you have to answer questions about that text, right?

00:10:37.380 --> 00:10:39.380
the thing that's fun is

00:10:40.140 --> 00:10:42.140
How do you do this

00:10:43.080 --> 00:10:44.460
Without

00:10:44.460 --> 00:10:47.539
Modifying your model. That's just a generative model

00:10:48.240 --> 00:10:50.240
This is where we start getting into

00:10:50.320 --> 00:10:56.940
So that's... you... by the time it's read it, it's modified itself based upon what you've given it to read? Is that what you mean?

00:10:57.420 --> 00:10:59.420
No, what I mean is

00:11:01.100 --> 00:11:02.300
The way that GPT 2 works is

00:11:03.180 --> 00:11:08.300
you give it the sequence of tokens and it gives you a probability distribution for the next token and

00:11:09.190 --> 00:11:12.390
so they're like type signature of that is

00:11:13.270 --> 00:11:16.739
totally fine with if you're trying to fill in a missing word or

00:11:17.470 --> 00:11:19.649
I guess I don't know how they did it for these

00:11:20.649 --> 00:11:22.649
for this test

00:11:26.890 --> 00:11:32.909
But you have to take you have to take the challenge that you're given and try and express it in terms of

00:11:33.339 --> 00:11:35.200
This like predict the next word

00:11:35.200 --> 00:11:35.860
type

00:11:35.860 --> 00:11:37.140
setup because otherwise

00:11:37.140 --> 00:11:42.179
You're sort of cheating, right? The whole thing is they're trying to go at this and not not modify the system at all. So

00:11:43.060 --> 00:11:45.010
for reading comprehension

00:11:45.010 --> 00:11:47.010
the way they do it is they

00:11:47.680 --> 00:11:49.360
give the

00:11:49.360 --> 00:11:51.360
thing bits to be comprehended and

00:11:51.820 --> 00:11:53.500
then they give

00:11:53.500 --> 00:11:58.679
Q : a question a : the correct answer to that question

00:11:59.320 --> 00:12:05.159
newline Q : a new question they give like three or four example questions and then

00:12:05.920 --> 00:12:10.020
Q : the question, they actually want answered a : let it generate

00:12:10.540 --> 00:12:13.680
So they sort of prime it I think we have some examples of this

00:12:13.680 --> 00:12:17.549
So this is how they did the question/answer thing. They gave these two paragraphs about

00:12:18.130 --> 00:12:19.510
the

00:12:19.510 --> 00:12:22.770
Olympic Games to torch relay moving the

00:12:23.230 --> 00:12:27.420
Olympic torch and I have some news story and then a bunch of questions right question

00:12:27.420 --> 00:12:31.950
What was the theme of the one world one dream and so on and so on and then at the end question and did they?

00:12:31.950 --> 00:12:34.349
climb any mountains and then a :

00:12:35.200 --> 00:12:37.200
Generate me the next word so they've used

00:12:38.200 --> 00:12:42.390
This the the input text to kind of prime the model

00:12:43.420 --> 00:12:47.190
Now we're doing question-answer pairs. This is how it works, right and

00:12:48.399 --> 00:12:54.089
The interesting thing about this is it actually ends up giving kind of a better answer than that human generated answers

00:12:54.279 --> 00:13:02.019
So the question did they climb any mountains the responses they got from humans were unknown. Yes. Yes, and yes because they do plain mountains

00:13:02.540 --> 00:13:04.520
but gbg to

00:13:04.520 --> 00:13:11.979
Dare answer is Everest. So gbt twos answer is actually kind of better than the humans. The humans just said, yes they did and

00:13:13.130 --> 00:13:18.729
the machine learning system has named the mountain that they climbed so I don't know if that's

00:13:20.090 --> 00:13:25.479
If that counts is not quite understanding the question or if that counts is actually providing a high-quality answer

00:13:25.520 --> 00:13:29.710
It's up for debate because it has this ability with attention to do the long range

00:13:29.840 --> 00:13:32.649
It has to look back past all of the previous questions

00:13:33.170 --> 00:13:38.800
To the actual paragraph and find the relevant information and it can do it and it performs reasonably. Well at that

00:13:39.620 --> 00:13:43.060
But the thing I love about that is that they have to like come up with tricks

00:13:43.490 --> 00:13:48.790
To get it to actually do the task that they're trying to get it to do. So the summarization one is brilliant

00:13:48.790 --> 00:13:52.779
I love the way they did this with the summarization. See if you can guess how they did this, right?

00:13:52.780 --> 00:13:54.620
You want to get a summary of?

00:13:54.620 --> 00:14:00.130
A piece of text. How do you how do you get that given a huge data set or edit?

00:14:00.770 --> 00:14:02.770
content and what you do is

00:14:02.780 --> 00:14:07.269
you write the whole long piece of text and then you put like a new line and then you put

00:14:07.640 --> 00:14:11.319
TL DR too long didn't read in this data set. There will be

00:14:11.540 --> 00:14:17.229
thousands and thousands of examples of long pieces of text followed by a short summary of that text and

00:14:17.390 --> 00:14:21.879
In the middle is this string TL DR? I would love to have been in the room when they thought of that

00:14:22.340 --> 00:14:24.340
So yeah, it's really

00:14:24.590 --> 00:14:28.299
Really cool really powerful technology. I like it a lot.

00:14:29.090 --> 00:14:36.249
So an executable binary the net effect of slotting that T diagram against here slightly downwards is to show you

00:14:37.580 --> 00:14:41.949
That the C you've written gets converted into binary and the net output

00:14:42.590 --> 00:14:47.979
from this process it produces out a program that you probably store in a

